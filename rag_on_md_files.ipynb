{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8873c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vineetdorikar/Developer/projects/RAG_blog_series/rag_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "#initializing embedding mdoel\n",
    "embed_model = HuggingFaceEmbedding(model_name='BAAI/bge-small-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09855918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "#initializing llm\n",
    "llm = Ollama(model=\"llama2\", request_timeout=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e65d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "#important parameters used for database connections\n",
    "db_name = 'md_vector_sore'\n",
    "host = 'localhost'\n",
    "user = 'vineet'\n",
    "password = 'password'\n",
    "port = '5432'\n",
    "\n",
    "#connecting to existing database named 'postgres'\n",
    "db = psycopg2.connect(\n",
    "    host=host,\n",
    "    database=\"postgres\",\n",
    "    user=user,\n",
    "    password=password,\n",
    "    port=port\n",
    ")\n",
    "\n",
    "# autocommit = true, cause create database and drop database commands \n",
    "# can not be executed in transaction state.\n",
    "db.autocommit = True\n",
    "\n",
    "#removing old database with same name and creating new database\n",
    "with db.cursor() as c:\n",
    "    c.execute(f\"DROP DATABASE IF EXISTS {db_name}\")\n",
    "    c.execute(f\"CREATE DATABASE {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e28b6de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import make_url\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "\n",
    "# creating vector database from our norimal database by using PGVectorStore\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=db_name,\n",
    "    host=host,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    port=port,\n",
    "    table_name=\"research paper\",\n",
    "    embed_dim=384\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca42ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# loading pdf's in our environment \n",
    "\n",
    "documents = SimpleDirectoryReader(\"~/obs_brain/BRAIN/Daily Writings\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10139a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# chunking or splitting our docs in smaller chunks\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "\n",
    "chunks = []\n",
    "chunk_idx = []\n",
    "\n",
    "for id, doc in enumerate(documents):\n",
    "    cur_chunks = splitter.split_text(doc.text)\n",
    "    chunks.extend(cur_chunks)\n",
    "    chunk_idx.extend([id]* len(cur_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90ce1794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "# saving those chunks as nodes \n",
    "\n",
    "nodes = []\n",
    "\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    node = TextNode(text=chunk)\n",
    "    src_doc = documents[chunk_idx[idx]]\n",
    "    node.metadata = src_doc.metadata\n",
    "    nodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3fe7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding part\n",
    "\n",
    "for node in nodes:\n",
    "    node_embedding = embed_model.get_text_embedding(node.get_content(metadata_mode=all))\n",
    "    node.embedding = node_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b4af2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_path': '/Users/vineetdorikar/obs_brain/BRAIN/Daily Writings/Feb 20, 2025.md', 'file_name': 'Feb 20, 2025.md', 'file_type': 'text/markdown', 'file_size': 129, 'creation_date': '2025-02-23', 'last_modified_date': '2025-02-23'}\n"
     ]
    }
   ],
   "source": [
    "print(nodes[6].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e315e500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5f8e5e82-3310-415c-8475-c92f0796c569',\n",
       " '9b449d1b-ceea-45d8-8dcc-063e180770cd',\n",
       " '828afe97-c438-45e5-b7ce-f837c41ebee4',\n",
       " '5459c4eb-9531-4d36-912b-fec6b5c70ed2',\n",
       " '3ce6090c-c29f-4e10-9dc6-76bee3756229',\n",
       " '532ee323-1595-47b0-b63f-c2947f128e78',\n",
       " 'aa9dd5c4-b199-42aa-9b92-5294a67ccb93',\n",
       " 'c6f80c3d-c896-4f41-a113-09db2d4ed009',\n",
       " '195b9533-4513-4e3c-8a5b-db8d62f7d4ea',\n",
       " '62dcb80e-46ce-4e06-bda8-068b4687e88b',\n",
       " '02e39ee8-18cd-42cf-951e-e2c1e122bee5',\n",
       " '579908ce-81a3-460e-823e-1a86f216709a',\n",
       " '7c200e9a-b1f0-4a37-a7c4-87d5ca1558c8',\n",
       " 'fda06b3e-d275-4b08-85a8-627c206cdb80',\n",
       " '44763a03-6648-4b54-9517-9210c2cb2f63',\n",
       " 'f0027a48-2270-46cd-be38-2e03951f994c',\n",
       " '90469dd0-7691-4069-b0e0-410e9ba54f8b',\n",
       " '26d64152-fe66-43d3-ab7d-05f475548966',\n",
       " '5dad613f-4857-4848-a876-769518e3fdd3',\n",
       " '735f64ad-fcec-4a48-937c-1025f6a06658',\n",
       " '502dcc67-8aa6-4609-892e-8c074879983d',\n",
       " '17ad981f-6df7-4291-9c1d-12e485c4706b',\n",
       " '45539063-af91-4884-8f1a-b37ec5e9f50c',\n",
       " '1a6b519a-49b1-48c0-946c-ddf93fc26fe6',\n",
       " 'c857d0ed-baeb-4755-885d-e8851a32eb51',\n",
       " 'bc71d1b5-880c-42b6-b076-6812d926c4fe',\n",
       " '2441f954-05c1-42b5-adf5-3d68e0b3c94d',\n",
       " 'd6a44383-3589-453e-9146-fe18e53eaf5a',\n",
       " 'e18ad296-a0d1-4aa5-a217-146d38a4b9ee',\n",
       " 'bc80b7fe-5342-4efa-946c-aeda9dac6d97',\n",
       " 'ab37b043-f5b9-48bc-ae26-6a5c3723fd3d',\n",
       " '224e33aa-3e4d-4cdb-868f-82d071c3938b',\n",
       " '33fb1251-1b6d-47ff-b509-82a43aab8571',\n",
       " 'ee5f7e5a-8763-42d5-96ba-01fd7337203f',\n",
       " '99734272-fa44-4e3a-8888-a50ce4acc0fd']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding all nodes to our vector database \n",
    "vector_store.add(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b4e60a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from typing import Any, List\n",
    "from llama_index.core import QueryBundle\n",
    "from llama_index.core.vector_stores import VectorStoreQuery\n",
    "\n",
    "# building custom retriver by inheriting BaseRetriever class\n",
    "\n",
    "class Retriever(BaseRetriever):\n",
    "    def __init__(self,\n",
    "                 vector_store : PGVectorStore,\n",
    "                 embed_model: any,\n",
    "                 query_mode: str = \"default\",\n",
    "                 similarity_top_k: int = 2) -> None:\n",
    "        self._vector_store = vector_store\n",
    "        self._embed_model = embed_model\n",
    "        self._query_mode = query_mode\n",
    "        self._similarity_top_k = similarity_top_k\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        query_embedding = embed_model.get_query_embedding(\n",
    "            query_bundle.query_str\n",
    "        )\n",
    "        vector_query_obj = VectorStoreQuery(\n",
    "            query_embedding=query_embedding,\n",
    "            similarity_top_k=self._similarity_top_k,\n",
    "            mode=self._query_mode\n",
    "        )\n",
    "        query_result = vector_store.query(vector_query_obj)\n",
    "\n",
    "        nodes_with_scores = []\n",
    "        for idx, node in enumerate(query_result.nodes):\n",
    "            if query_result.similarities is not None:\n",
    "                score = query_result.similarities[idx]\n",
    "\n",
    "            nodes_with_scores.append(NodeWithScore(node=node, score=score))\n",
    "\n",
    "        return nodes_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "507d0cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = Retriever(vector_store, embed_model, similarity_top_k=2, query_mode=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a48dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever=retriever, llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382e013b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vineet did not directly state what he did when he met his old friends, but based on the context, it can be inferred that he hung out with them outside in the front yard of their house while he was feeling unwell due to a cold. He described the experience as \"pretty chill\" and good to see his old friends, but also mentioned that one line said by one of his friends, Shivam, made him uncomfortable and left a bitter taste in his mouth.\n"
     ]
    }
   ],
   "source": [
    "query_str = \"why \"\n",
    "\n",
    "query_response = query_engine.query(query_str)\n",
    "\n",
    "print(str(query_response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
